{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm \n",
    "import os\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD, NMF, SlopeOne, CoClustering    \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/data_for_model/data_for_model.pkl', 'rb') as f:\n",
    "    # Load the contents of the file using pickle.load()\n",
    "    data_for_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo = KNNBasic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['recalls_list','precs_list','result_all']\n",
    "names_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to load all pickle files to later turn into dataframe\n",
    "data_dir = '../data/'\n",
    "folder_list = [i for i in os.listdir(data_dir) if i not in ['.ipynb_checkpoints','input','data_for_model','no_null_user_ratings']]\n",
    "for i in folder_list:\n",
    "    x = f\"{data_dir}{i}\"\n",
    "    for enum_num,enum_name in enumerate(names):\n",
    "        file_path = f\"{x}/{enum_num}.pickle\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            names_dict[enum_name].append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {}\n",
    "for sublist in names_dict['result_all']:\n",
    "    for algorithm, score in sublist:\n",
    "        if algorithm not in averages:\n",
    "            averages[algorithm] = score\n",
    "        else:\n",
    "            averages[algorithm].append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVD': [1.0213712081874704,\n",
       "  [1.0204828673113941],\n",
       "  [1.0203655120368236],\n",
       "  [1.0200507047167389],\n",
       "  [1.0200749272648115]],\n",
       " 'NonNegative Matrix Factorization': [1.7844759821295415,\n",
       "  [1.777024081528765],\n",
       "  [1.7885889749663555],\n",
       "  [1.7871589997098034],\n",
       "  [1.785430450313568]],\n",
       " 'Slope One': [1.0174268302254594,\n",
       "  [1.0175506091427093],\n",
       "  [1.0174059117435126],\n",
       "  [1.0175889050438958],\n",
       "  [1.0175749963301826]],\n",
       " 'Co-clustering': [1.045843777282942,\n",
       "  [1.0469009270176166],\n",
       "  [1.045874629570217],\n",
       "  [1.0448459966189174],\n",
       "  [1.0448217456155375]],\n",
       " 'Baseline': [1.0205603642904433,\n",
       "  [1.0204669150813224],\n",
       "  [1.0205703614676553],\n",
       "  [1.0206715940241646],\n",
       "  [1.0205877974894502]],\n",
       " 'Normal_predictor': [1.851355658968064,\n",
       "  [1.854540711200352],\n",
       "  [1.8519912733150865],\n",
       "  [1.8551386751747798],\n",
       "  [1.8539058727766673]],\n",
       " 'KNNBasic': [1.0719991243168838,\n",
       "  [1.0720212512429264],\n",
       "  [1.0720624660482645],\n",
       "  [1.0717710467632777],\n",
       "  [1.0717790416347135]],\n",
       " 'KNNBaseline': [1.0162666704578496,\n",
       "  [1.0163140169410112],\n",
       "  [1.0161297983003117],\n",
       "  [1.01603754731909],\n",
       "  [1.0162251136798275]],\n",
       " 'KNNWithMeans': [1.0322930298413733,\n",
       "  [1.0325650866738545],\n",
       "  [1.0323758873182522],\n",
       "  [1.0324132364574552],\n",
       "  [1.032247415337125]],\n",
       " 'KNNWithZScore': [1.0322678597783477,\n",
       "  [1.03182707353962],\n",
       "  [1.032020199765125],\n",
       "  [1.0319876956156826],\n",
       "  [1.031992086347868]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "for algorithm, scores in averages.items():\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    rmse_dict[algorithm] =  average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVD': 1.0204690439034478,\n",
       " 'NonNegative Matrix Factorization': 1.7845356977296067,\n",
       " 'Slope One': 1.017509450497152,\n",
       " 'Co-clustering': 1.045657415221046,\n",
       " 'Baseline': 1.020571406470607,\n",
       " 'Normal_predictor': 1.85338643828699,\n",
       " 'KNNBasic': 1.0719265860012133,\n",
       " 'KNNBaseline': 1.0161946293396178,\n",
       " 'KNNWithMeans': 1.0323789311256122,\n",
       " 'KNNWithZScore': 1.0320189830093287}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recalls_dict = {model_name: recall_score for recall_list in \n",
    "                names_dict['recalls_list'] \n",
    "                for model_name, recall_score in recall_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs_dict = {model_name: recall_score for recall_list in \n",
    "                names_dict['precs_list'] \n",
    "                for model_name, recall_score in recall_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVD': 1.0204690439034478,\n",
       " 'NonNegative Matrix Factorization': 1.7845356977296067,\n",
       " 'Slope One': 1.017509450497152,\n",
       " 'Co-clustering': 1.045657415221046,\n",
       " 'Baseline': 1.020571406470607,\n",
       " 'Normal_predictor': 1.85338643828699,\n",
       " 'KNNBasic': 1.0719265860012133,\n",
       " 'KNNBaseline': 1.0161946293396178,\n",
       " 'KNNWithMeans': 1.0323789311256122,\n",
       " 'KNNWithZScore': 1.0320189830093287}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = [recalls_dict,precs_dict,rmse_dict]\n",
    "dataframe_results = pd.DataFrame(dict_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_results.rename(columns={0:'recall_at_k',1:'precision_at_k',2:'average_rmse'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final = dataframe_results[['precision_at_k','recall_at_k','average_rmse']].sort_values('precision_at_k',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>average_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.698465</td>\n",
       "      <td>0.428652</td>\n",
       "      <td>1.071927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.698177</td>\n",
       "      <td>0.390089</td>\n",
       "      <td>1.020469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.688521</td>\n",
       "      <td>0.356677</td>\n",
       "      <td>1.016195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.686130</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>1.020571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.683345</td>\n",
       "      <td>0.367066</td>\n",
       "      <td>1.032019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope One</th>\n",
       "      <td>0.679875</td>\n",
       "      <td>0.360517</td>\n",
       "      <td>1.017509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Co-clustering</th>\n",
       "      <td>0.665922</td>\n",
       "      <td>0.333746</td>\n",
       "      <td>1.045657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.661810</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>1.032379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal_predictor</th>\n",
       "      <td>0.465807</td>\n",
       "      <td>0.314209</td>\n",
       "      <td>1.853386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NonNegative Matrix Factorization</th>\n",
       "      <td>0.087494</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>1.784536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision_at_k  recall_at_k  average_rmse\n",
       "KNNBasic                                0.698465     0.428652      1.071927\n",
       "SVD                                     0.698177     0.390089      1.020469\n",
       "KNNBaseline                             0.688521     0.356677      1.016195\n",
       "Baseline                                0.686130     0.367994      1.020571\n",
       "KNNWithZScore                           0.683345     0.367066      1.032019\n",
       "Slope One                               0.679875     0.360517      1.017509\n",
       "Co-clustering                           0.665922     0.333746      1.045657\n",
       "KNNWithMeans                            0.661810     0.334689      1.032379\n",
       "Normal_predictor                        0.465807     0.314209      1.853386\n",
       "NonNegative Matrix Factorization        0.087494     0.009557      1.784536"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_final.to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are more concerned from a business standpoint of the overall precision of our model (the number of relevant predictions to our user) we use that as our most important metric as the difference between models is neglible at \n",
    "a 0.5% change in rmse.\n",
    "\n",
    "Our strongest two models were SVD and KNNBasic.\n",
    "\n",
    "When choosing between two recommendation models, SVD and KNNBasic we can see  and their overall RMSE and Precision@K are similar, but KNNBasic has a better Recall@K we chose KNNBasic over SVD by considering the following:\n",
    "\n",
    "Recall is a measure of the fraction of relevant items that were recommended to the user, out of all relevant items. A higher recall means that more relevant items were recommended to the user.\n",
    "\n",
    "Overall, if recall is more important for your application and you have a high degree of user-item sparsity, KNNBasic is the better as compared to SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As concluded above, we go with KNNBasic based on the strongest precision and recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNNBasic()\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(data_for_model[['Username','BGGId', 'Rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x21f42005a00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=data.build_full_trainset()\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_csv2 = pd.read_csv('../data/no_null_user_ratings/games_after_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "user_list = []\n",
    "game_list = data_for_model[data_for_model['Username'] == 'Evabelle']['BGGId'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_user_list = [i for i in games_csv2['BGGId'].to_list() if i not in game_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = [model.predict(uid='Evabelle', iid=i) for i in not_user_list]\n",
    "est = [i.est for i in predict_list if i.details['was_impossible'] !=True]\n",
    "iids = [i.iid for i in predict_list if i.details['was_impossible'] !=True]\n",
    "\n",
    "test_df = pd.DataFrame({'est': est,\n",
    "              'BGGId': iids}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(test_df, games_csv2, on='BGGId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>BGGId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.967750</td>\n",
       "      <td>284121</td>\n",
       "      <td>Uprising: Curse of the Last Emperor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.561072</td>\n",
       "      <td>342942</td>\n",
       "      <td>Ark Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.546281</td>\n",
       "      <td>295785</td>\n",
       "      <td>Euthia: Torment of Resurrection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.252500</td>\n",
       "      <td>341169</td>\n",
       "      <td>Great Western Trail (Second Edition)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.146072</td>\n",
       "      <td>237828</td>\n",
       "      <td>Anno Domini 1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.104490</td>\n",
       "      <td>249277</td>\n",
       "      <td>Brazil: Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.095526</td>\n",
       "      <td>209951</td>\n",
       "      <td>Thunder in the East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.948703</td>\n",
       "      <td>299317</td>\n",
       "      <td>Aeon's End: Outcasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.934255</td>\n",
       "      <td>277659</td>\n",
       "      <td>Final Girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.932701</td>\n",
       "      <td>299659</td>\n",
       "      <td>Clash of Cultures: Monumental Edition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        est   BGGId                                   Name\n",
       "0  9.967750  284121    Uprising: Curse of the Last Emperor\n",
       "1  9.561072  342942                               Ark Nova\n",
       "2  9.546281  295785        Euthia: Torment of Resurrection\n",
       "3  9.252500  341169   Great Western Trail (Second Edition)\n",
       "4  9.146072  237828                       Anno Domini 1666\n",
       "5  9.104490  249277                       Brazil: Imperial\n",
       "6  9.095526  209951                    Thunder in the East\n",
       "7  8.948703  299317                   Aeon's End: Outcasts\n",
       "8  8.934255  277659                             Final Girl\n",
       "9  8.932701  299659  Clash of Cultures: Monumental Edition"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['est','BGGId','Name']].sort_values('est',ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demoing on new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "bgg_id_demo = []\n",
    "rating_demo = []\n",
    "for i in range(5):\n",
    "    bgg_id_demo.append(random.choice(data_for_model['BGGId']))\n",
    "    rating_demo.append(random.uniform(5.0, 10.0))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.7757680277325285,\n",
       " 7.090790479541342,\n",
       " 5.556141574921927,\n",
       " 7.476484376301415,\n",
       " 7.600644140707615]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a deployment standpoint, we need to make sure that our model is able to output recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new_user = pd.DataFrame([], columns=['BGGId','Rating','Username'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_user['BGGId'] = bgg_id_demo\n",
    "df_new_user['Rating'] = rating_demo\n",
    "df_new_user['Username'] = 'demo_user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.concat([data_for_model,df_new_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNNBasic()\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data_2 = Dataset.load_from_df(demo_df[['Username','BGGId', 'Rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x21f5cf549a0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=data_2.build_full_trainset()\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = [model.predict(uid='demo_user', iid=i) for i in not_user_list]\n",
    "est = [i.est for i in predict_list if i.details['was_impossible'] !=True]\n",
    "iids = [i.iid for i in predict_list if i.details['was_impossible'] !=True]\n",
    "\n",
    "demo_test_df = pd.DataFrame({'est': est,\n",
    "              'BGGId': iids}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2 = pd.merge(demo_test_df, games_csv2, on='BGGId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>BGGId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.967750</td>\n",
       "      <td>284121</td>\n",
       "      <td>Uprising: Curse of the Last Emperor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.561072</td>\n",
       "      <td>342942</td>\n",
       "      <td>Ark Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.546281</td>\n",
       "      <td>295785</td>\n",
       "      <td>Euthia: Torment of Resurrection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.252500</td>\n",
       "      <td>341169</td>\n",
       "      <td>Great Western Trail (Second Edition)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.146072</td>\n",
       "      <td>237828</td>\n",
       "      <td>Anno Domini 1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.104490</td>\n",
       "      <td>249277</td>\n",
       "      <td>Brazil: Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.095526</td>\n",
       "      <td>209951</td>\n",
       "      <td>Thunder in the East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.948703</td>\n",
       "      <td>299317</td>\n",
       "      <td>Aeon's End: Outcasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.934255</td>\n",
       "      <td>277659</td>\n",
       "      <td>Final Girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.932701</td>\n",
       "      <td>299659</td>\n",
       "      <td>Clash of Cultures: Monumental Edition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        est   BGGId                                   Name\n",
       "0  9.967750  284121    Uprising: Curse of the Last Emperor\n",
       "1  9.561072  342942                               Ark Nova\n",
       "2  9.546281  295785        Euthia: Torment of Resurrection\n",
       "3  9.252500  341169   Great Western Trail (Second Edition)\n",
       "4  9.146072  237828                       Anno Domini 1666\n",
       "5  9.104490  249277                       Brazil: Imperial\n",
       "6  9.095526  209951                    Thunder in the East\n",
       "7  8.948703  299317                   Aeon's End: Outcasts\n",
       "8  8.934255  277659                             Final Girl\n",
       "9  8.932701  299659  Clash of Cultures: Monumental Edition"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_2[['est','BGGId','Name','']].sort_values('est',ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is a powerful tool that is capable of providing highly accurate recommendations for users, making it an invaluable asset to the platform. As users become more active and leave more reviews, our model's ability to provide insightful and relevant recommendations will only increase, resulting in even greater user satisfaction.\n",
    "\n",
    "Furthermore, by leveraging our model to increase user engagement, the platform stands to benefit tremendously. With its ability to provide solid recommendations based on users' prior reviews, our model can help to create a more personalized and engaging experience for users, ultimately leading to greater retention and loyalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model did not fully utilise all data avalabile dataset in the dataset to train the recommender system, and thus acts on the assumption the interest of our user is only limited to games released in the last 5 years. \n",
    "\n",
    "Due to computational limitations precision was priortised over recall for this model.\n",
    "\n",
    "Filtering the dataset to games that are reviewed more than 100 times and users with 100 or more reviews can help improve data quality and reduce noise. However, it can also limit coverage, user behavior, and lead to data sparsity, which can negatively impact the performance of the Recall@k metric, as well as a cold start problem as similarly to most collaborative filtering recommender algorithims. \n",
    "\n",
    "For new users, the recommender system has no historical data on which to base recommendations, and therefore cannot make accurate predictions. Similarly, for new items, the recommender system has no prior information on which to base recommendations, and therefore cannot identify which users might be interested in the item.\n",
    "\n",
    "The model, would require constant retraining to keep up to date with all new users inorder to mantain the quality of the recommender systems.\n",
    "\n",
    "\n",
    "\n",
    "Future work could involve a model that can account for more than the users and reviews, such as pytorch's recommendation module, as well as using big data tools such as PySpark that allows us to train models on large datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
