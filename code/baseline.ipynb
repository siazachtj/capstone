{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1d36aa-873f-41e4-a0e8-25d2cc3231e9",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4bdff-93df-41da-9b2d-169b86ec51ba",
   "metadata": {},
   "source": [
    "Now that we have our threshold (refer to last line in our EDA Part2) and our definitions we will begin modelling our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a180e01e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-27T04:42:32.502724Z",
     "iopub.status.busy": "2023-02-27T04:42:32.501686Z",
     "iopub.status.idle": "2023-02-27T04:42:34.351150Z",
     "shell.execute_reply": "2023-02-27T04:42:34.349045Z"
    },
    "papermill": {
     "duration": 1.868058,
     "end_time": "2023-02-27T04:42:34.354828",
     "exception": false,
     "start_time": "2023-02-27T04:42:32.486770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/user-ratings/user_ratings.csv\n",
      "/kaggle/input/games-after-2010/games_after_2010.csv\n",
      "/kaggle/input/df-for-model/df_for_modelling.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm \n",
    "import os\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD, NMF, SlopeOne, CoClustering    \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5280e-736c-49b7-a484-10ef382876d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..data/data_for_model/data_for_model.pkl', 'rb') as f:\n",
    "    # Load the contents of the file using pickle.load()\n",
    "    data_for_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bea6a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:43:01.211391Z",
     "iopub.status.busy": "2023-02-27T04:43:01.210578Z",
     "iopub.status.idle": "2023-02-27T04:43:01.215893Z",
     "shell.execute_reply": "2023-02-27T04:43:01.214641Z"
    },
    "papermill": {
     "duration": 0.024139,
     "end_time": "2023-02-27T04:43:01.218515",
     "exception": false,
     "start_time": "2023-02-27T04:43:01.194376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "algos = [('Baseline',BaselineOnly()),('Normal_predictor',NormalPredictor())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63c338ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:43:01.339209Z",
     "iopub.status.busy": "2023-02-27T04:43:01.338345Z",
     "iopub.status.idle": "2023-02-27T04:43:02.652512Z",
     "shell.execute_reply": "2023-02-27T04:43:02.651174Z"
    },
    "papermill": {
     "duration": 1.333675,
     "end_time": "2023-02-27T04:43:02.655632",
     "exception": false,
     "start_time": "2023-02-27T04:43:01.321957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(data_for_model[['Username','BGGId', 'Rating']],reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f2ec3-1b1f-4373-b46a-6fc7bf54e787",
   "metadata": {},
   "source": [
    "Using the recommended metrics by scikit suprise, we will be using recall@k and precision@k to compute the performance of our model. Precision is essentially how many of our predictions our model gave us that we deemed to be relevant to our user in our top 'k' recommendations. Recall is essentially how many of the predictions our model gave out of all relevant items in our top 'k' recommendations, essentially the variability of our recommendation when looking at all relevant recommendations as a whole.\n",
    "\n",
    "In our specific use case our threshold would be 7.5 and our k will be set to 10.\n",
    "\n",
    "Refer to the following [link](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54) for a more detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f5111d",
   "metadata": {
    "papermill": {
     "duration": 0.032277,
     "end_time": "2023-02-27T04:43:02.783743",
     "exception": false,
     "start_time": "2023-02-27T04:43:02.751466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-compute-precision-k-and-recall-k'''\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab2350-1ca0-479e-8fe6-dcef477b1ef2",
   "metadata": {},
   "source": [
    "We used a 5 fold cross validation to train and test our model to determine the metrics we want including our loss (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "450c7766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:43:02.931361Z",
     "iopub.status.busy": "2023-02-27T04:43:02.930877Z",
     "iopub.status.idle": "2023-02-27T04:50:52.188127Z",
     "shell.execute_reply": "2023-02-27T04:50:52.186678Z"
    },
    "papermill": {
     "duration": 469.294653,
     "end_time": "2023-02-27T04:50:52.208936",
     "exception": false,
     "start_time": "2023-02-27T04:43:02.914283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0196  1.0223  1.0226  1.0196  1.0187  1.0206  0.0016  \n",
      "MAE (testset)     0.7591  0.7600  0.7624  0.7593  0.7600  0.7602  0.0012  \n",
      "Fit time          3.46    3.81    4.22    3.81    3.83    3.83    0.24    \n",
      "Test time         1.77    1.73    2.30    1.76    1.72    1.86    0.22    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0193  1.0246  1.0198  1.0203  1.0183  1.0205  0.0022  \n",
      "MAE (testset)     0.7603  0.7623  0.7590  0.7603  0.7587  0.7601  0.0013  \n",
      "Fit time          3.67    3.98    4.00    3.99    3.96    3.92    0.13    \n",
      "Test time         1.77    1.81    1.76    2.34    1.74    1.88    0.23    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0202  1.0181  1.0199  1.0230  1.0216  1.0206  0.0017  \n",
      "MAE (testset)     0.7602  0.7596  0.7588  0.7615  0.7604  0.7601  0.0009  \n",
      "Fit time          3.65    3.91    4.12    3.97    4.41    4.01    0.25    \n",
      "Test time         1.88    1.76    1.77    2.36    1.78    1.91    0.23    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0198  1.0188  1.0198  1.0264  1.0186  1.0207  0.0029  \n",
      "MAE (testset)     0.7587  0.7596  0.7602  0.7626  0.7599  0.7602  0.0013  \n",
      "Fit time          3.68    3.91    3.98    3.87    4.01    3.89    0.12    \n",
      "Test time         1.81    1.76    2.33    1.78    1.73    1.88    0.23    \n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0201  1.0176  1.0216  1.0205  1.0230  1.0206  0.0018  \n",
      "MAE (testset)     0.7612  0.7584  0.7610  0.7594  0.7611  0.7602  0.0011  \n",
      "Fit time          3.63    3.90    3.93    3.95    4.09    3.90    0.15    \n",
      "Test time         1.76    1.71    2.31    1.74    1.75    1.86    0.23    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8523  1.8472  1.8520  1.8532  1.8520  1.8514  0.0021  \n",
      "MAE (testset)     1.4629  1.4576  1.4630  1.4639  1.4620  1.4619  0.0022  \n",
      "Fit time          1.66    1.97    1.91    1.93    1.94    1.88    0.11    \n",
      "Test time         2.32    2.89    2.30    2.96    2.29    2.55    0.31    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8559  1.8500  1.8572  1.8570  1.8526  1.8545  0.0028  \n",
      "MAE (testset)     1.4656  1.4596  1.4655  1.4639  1.4628  1.4635  0.0022  \n",
      "Fit time          1.64    1.97    1.95    1.94    1.94    1.89    0.13    \n",
      "Test time         2.32    2.92    2.30    2.25    2.98    2.56    0.32    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8524  1.8491  1.8489  1.8534  1.8561  1.8520  0.0027  \n",
      "MAE (testset)     1.4633  1.4599  1.4611  1.4630  1.4649  1.4624  0.0017  \n",
      "Fit time          1.61    1.95    1.98    1.96    1.94    1.89    0.14    \n",
      "Test time         3.00    2.31    2.28    2.92    2.31    2.56    0.33    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8567  1.8557  1.8547  1.8555  1.8530  1.8551  0.0012  \n",
      "MAE (testset)     1.4651  1.4644  1.4634  1.4659  1.4631  1.4644  0.0010  \n",
      "Fit time          1.69    2.12    2.19    2.04    1.98    2.00    0.17    \n",
      "Test time         2.35    2.37    3.29    2.34    2.32    2.53    0.38    \n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8511  1.8480  1.8620  1.8543  1.8541  1.8539  0.0047  \n",
      "MAE (testset)     1.4616  1.4592  1.4704  1.4640  1.4648  1.4640  0.0038  \n",
      "Fit time          1.66    1.98    1.95    2.01    1.93    1.91    0.13    \n",
      "Test time         2.34    3.03    2.29    2.31    2.28    2.45    0.29    \n"
     ]
    }
   ],
   "source": [
    "# # # # #############really need to sort this out ####################\n",
    "precs_list = []\n",
    "recalls_list = []\n",
    "kf = KFold(n_splits=5,random_state=42)\n",
    "result_all = []\n",
    "for var_name,model in algos:\n",
    "    temp_prec_list = []\n",
    "    temp_recall_list = []\n",
    "    for trainset, testset in kf.split(data):\n",
    "        temp_result= []\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=7.5)\n",
    "        result = cross_validate(model,data,measures=['RMSE','MAE'],cv=5,verbose=True)\n",
    "        temp_result.append(result['test_rmse'].mean())\n",
    "        result_all.append((var_name,temp_result))\n",
    "    # Precision and recall can then be averaged over all users\n",
    "        temp_prec_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        temp_recall_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    precs_list.append((var_name,np.mean(temp_prec_list)))\n",
    "    recalls_list.append((var_name,np.mean(temp_recall_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b4326d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:50:52.248949Z",
     "iopub.status.busy": "2023-02-27T04:50:52.248475Z",
     "iopub.status.idle": "2023-02-27T04:50:52.254761Z",
     "shell.execute_reply": "2023-02-27T04:50:52.253798Z"
    },
    "papermill": {
     "duration": 0.029827,
     "end_time": "2023-02-27T04:50:52.257623",
     "exception": false,
     "start_time": "2023-02-27T04:50:52.227796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baseline', 0.3679935196001593), ('Normal_predictor', 0.31420880432844184)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf52a655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:50:52.297941Z",
     "iopub.status.busy": "2023-02-27T04:50:52.297105Z",
     "iopub.status.idle": "2023-02-27T04:50:52.303998Z",
     "shell.execute_reply": "2023-02-27T04:50:52.302963Z"
    },
    "papermill": {
     "duration": 0.028509,
     "end_time": "2023-02-27T04:50:52.306448",
     "exception": false,
     "start_time": "2023-02-27T04:50:52.277939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baseline', 0.6861302490644018), ('Normal_predictor', 0.4658070331655703)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17c66fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:50:52.343981Z",
     "iopub.status.busy": "2023-02-27T04:50:52.343246Z",
     "iopub.status.idle": "2023-02-27T04:50:52.351162Z",
     "shell.execute_reply": "2023-02-27T04:50:52.350110Z"
    },
    "papermill": {
     "duration": 0.02925,
     "end_time": "2023-02-27T04:50:52.353445",
     "exception": false,
     "start_time": "2023-02-27T04:50:52.324195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baseline', [1.0205603642904433]),\n",
       " ('Baseline', [1.0204669150813224]),\n",
       " ('Baseline', [1.0205703614676553]),\n",
       " ('Baseline', [1.0206715940241646]),\n",
       " ('Baseline', [1.0205877974894502]),\n",
       " ('Normal_predictor', [1.851355658968064]),\n",
       " ('Normal_predictor', [1.854540711200352]),\n",
       " ('Normal_predictor', [1.8519912733150865]),\n",
       " ('Normal_predictor', [1.8551386751747798]),\n",
       " ('Normal_predictor', [1.8539058727766673])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc4752b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:50:52.392679Z",
     "iopub.status.busy": "2023-02-27T04:50:52.392252Z",
     "iopub.status.idle": "2023-02-27T04:50:52.398887Z",
     "shell.execute_reply": "2023-02-27T04:50:52.397463Z"
    },
    "papermill": {
     "duration": 0.02967,
     "end_time": "2023-02-27T04:50:52.401469",
     "exception": false,
     "start_time": "2023-02-27T04:50:52.371799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def pickle_lists(list_of_lists):\n",
    "    for i, sublist in enumerate(list_of_lists):\n",
    "        with open(f\"../data/pickled_baseline/{i}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(sublist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdc459da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T04:50:52.439057Z",
     "iopub.status.busy": "2023-02-27T04:50:52.438577Z",
     "iopub.status.idle": "2023-02-27T04:50:52.444981Z",
     "shell.execute_reply": "2023-02-27T04:50:52.443786Z"
    },
    "papermill": {
     "duration": 0.028832,
     "end_time": "2023-02-27T04:50:52.448114",
     "exception": false,
     "start_time": "2023-02-27T04:50:52.419282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_lists([recalls_list,precs_list,result_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe1ac2-5557-489f-80ba-0b27a1413df1",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3eee3c-39ff-40fa-95ab-2aa43636561c",
   "metadata": {},
   "source": [
    "Due to computational constraints(long run time and memory errors) our modelling and metrics will be done in seperate notebooks and the data was pickled for further examination in model_final notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 515.559545,
   "end_time": "2023-02-27T04:50:55.091480",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-27T04:42:19.531935",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
